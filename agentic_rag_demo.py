import streamlit as st
from openai import OpenAI
import weaviate
from sqlalchemy import create_engine, text
import networkx as nx

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
client = OpenAI(
    api_key="sk-2D0EZSwcWUcD4c2K59353b7214854bBd8f35Ac131564EfBa",
    base_url="https://free.gpt.ge/v1"
)

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="Agentic RAG ç³»ç»Ÿ", layout="wide")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

def get_vector_search_results(query: str) -> list:
    try:
        # è¿™é‡Œæ·»åŠ å®é™…çš„WeaviateæŸ¥è¯¢é€»è¾‘
        return ["å‘é‡æœç´¢ç»“æœç¤ºä¾‹"]
    except Exception as e:
        st.error(f"å‘é‡æœç´¢é”™è¯¯: {str(e)}")
        return []

def get_rdb_search_results(query: str) -> list:
    try:
        # è¿™é‡Œæ·»åŠ å®é™…çš„æ•°æ®åº“æŸ¥è¯¢é€»è¾‘
        return ["å…³ç³»æ•°æ®åº“æœç´¢ç»“æœç¤ºä¾‹"]
    except Exception as e:
        st.error(f"æ•°æ®åº“æœç´¢é”™è¯¯: {str(e)}")
        return []

def get_graph_search_results(query: str) -> list:
    try:
        # è¿™é‡Œæ·»åŠ å®é™…çš„å›¾æ•°æ®åº“æŸ¥è¯¢é€»è¾‘
        return ["å›¾æ•°æ®åº“æœç´¢ç»“æœç¤ºä¾‹"]
    except Exception as e:
        st.error(f"å›¾æ•°æ®åº“æœç´¢é”™è¯¯: {str(e)}")
        return []

def get_llm_response(query: str, search_results: dict) -> str:
    try:
        # æ„å»ºæç¤ºè¯
        prompt = f"""
        æŸ¥è¯¢: {query}
        æœç´¢ç»“æœ:
        å‘é‡æœç´¢: {search_results['vector']}
        å…³ç³»æ•°æ®åº“: {search_results['rdb']}
        å›¾æ•°æ®åº“: {search_results['graph']}
        
        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ç”Ÿæˆå›ç­”ã€‚
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"LLMå“åº”é”™è¯¯: {str(e)}")
        return "æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°é”™è¯¯ã€‚"

# ä¸»ç•Œé¢
st.title("ğŸ¤– Agentic RAG ç³»ç»Ÿ")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("ç³»ç»Ÿé…ç½®")
    search_methods = st.multiselect(
        "é€‰æ‹©æœç´¢æ–¹æ³•",
        ["å‘é‡æœç´¢", "å…³ç³»æ•°æ®åº“", "å›¾æ•°æ®åº“"],
        default=["å‘é‡æœç´¢", "å…³ç³»æ•°æ®åº“", "å›¾æ•°æ®åº“"]
    )

# ä¸»è¦å†…å®¹åŒºåŸŸ
query = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š")

if st.button("æœç´¢å¹¶ç”Ÿæˆ"):
    with st.spinner("æ­£åœ¨å¤„ç†..."):
        # æ‰§è¡Œæœç´¢
        search_results = {
            "vector": get_vector_search_results(query) if "å‘é‡æœç´¢" in search_methods else [],
            "rdb": get_rdb_search_results(query) if "å…³ç³»æ•°æ®åº“" in search_methods else [],
            "graph": get_graph_search_results(query) if "å›¾æ•°æ®åº“" in search_methods else []
        }
        
        # è·å–LLMå“åº”
        response = get_llm_response(query, search_results)
        
        # æ›´æ–°å¯¹è¯å†å²
        st.session_state.chat_history.append({"query": query, "response": response})

# æ˜¾ç¤ºå¯¹è¯å†å²
st.subheader("å¯¹è¯å†å²")
for chat in st.session_state.chat_history:
    st.text_area("é—®é¢˜ï¼š", chat["query"], height=50, disabled=True)
    st.text_area("å›ç­”ï¼š", chat["response"], height=100, disabled=True)
    st.markdown("---") 