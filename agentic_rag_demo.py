import streamlit as st
import sqlite3
from openai import OpenAI
import networkx as nx
import pdfplumber
from datetime import datetime
import re
from vector_store import (
    vectorize_document, 
    search_similar, 
    num_tokens_from_string,
    init_pinecone,
    get_vector_search_results
)
import pandas as pd
import json
import os
from pymongo import MongoClient
from bson import json_util
import time
import traceback

def check_data_initialized():
    """æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®"""
    try:
        db = get_mongodb_connection()
        if db is None:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        count = db.patients.count_documents({})
        return count > 0
    except Exception as e:
        st.error(f"æ£€æŸ¥æ•°æ®åˆå§‹åŒ–çŠ¶æ€é”™è¯¯: {str(e)}")
        return False

def get_mongodb_connection():
    """è·å–MongoDBè¿æ¥å¹¶æµ‹è¯•è¿æ¥"""
    # å¦‚æœå·²ç»æœ‰è¿æ¥ï¼Œç›´æ¥è¿”å›
    if 'mongodb_connection' in st.session_state:
        return st.session_state.mongodb_connection
    
    try:
        client = MongoClient(
            "mongodb+srv://alantany:Mikeno01@airss.ykc1h.mongodb.net/ai-news?retryWrites=true&w=majority&appName=MedicalRAG",
            tlsAllowInvalidCertificates=True
        )
        # æµ‹è¯•è¿æ¥
        client.server_info()
        db = client['medical_records']
        st.write("âœ… MongoDBè¿æ¥æˆåŠŸ")
        # ä¿å­˜è¿æ¥åˆ°session_state
        st.session_state.mongodb_connection = db
        return db
    except Exception as e:
        st.error(f"MongoDBè¿æ¥é”™è¯¯: {str(e)}")
        return None

def get_structured_data(text: str) -> dict:
    """ä½¿ç”¨LLMæå–åŒ»ç–—ç›¸å…³çš„ç»“æ„åŒ–æ•°æ®"""
    try:
        # æ—§çš„é…ç½®
        # client = OpenAI(
        #     api_key="sk-2D0EZSwcWUcD4c2K59353b7214854bBd8f35Ac131564EfBa",
        #     base_url="https://free.gpt.ge/v1"
        # )
        
        # æ–°çš„é…ç½®
        client = OpenAI(
            api_key="sk-1pUmQlsIkgla3CuvKTgCrzDZ3r0pBxO608YJvIHCN18lvOrn",
            base_url="https://api.chatanywhere.tech/v1"
        )
        
        # è¯»å–ç¤ºä¾‹JSON
        with open('get_inf.json', 'r', encoding='utf-8') as f:
            example_json = f.read()
        
        prompt = """è¯·å‚ç…§ä»¥ä¸‹ç¤ºä¾‹JSONæ ¼å¼ï¼Œä»åŒ»ç–—ç—…å†ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚

ç¤ºä¾‹JSONæ ¼å¼ï¼š
{example_json}

ç—…å†å†…å®¹ï¼š
{text}

è¯·ä¸¥æ ¼æŒ‰ç…§ç¤ºä¾‹JSONçš„æ ¼å¼æå–ä¿¡æ¯ï¼Œæ³¨æ„ï¼š
1. ä½¿ç”¨ç›¸åŒçš„ä¸­æ–‡å­—æ®µå
2. å®Œå…¨ç›¸åŒçš„æ•°æ®ç»“æ„å±‚æ¬¡
3. æå–æ‰€æœ‰å¯èƒ½çš„æ£€éªŒæŒ‡æ ‡å’Œå…·ä½“æ•°å€¼
4. ä¿ç•™æ•°å€¼çš„ç²¾ç¡®åº¦å’Œå•ä½
5. å¯¹äºæ•°ç»„ç±»å‹çš„å­—æ®µï¼ˆå¦‚"ç°ç—…å²"ã€"å…¥é™¢è¯Šæ–­"ç­‰ï¼‰ï¼Œå°½å¯èƒ½å®Œæ•´åœ°åˆ—å‡ºæ‰€æœ‰é¡¹ç›®
6. ä¿æŒæ—¥æœŸæ ¼å¼çš„ç»Ÿä¸€ï¼ˆYYYY-MM-DDï¼‰
7. ç¡®ä¿ç”Ÿæˆçš„æ˜¯åˆæ³•çš„JSONæ ¼å¼
8. ä½¿ç”¨nullè¡¨ç¤ºç¼ºå¤±çš„ä¿¡æ¯
9. ç‰¹åˆ«æ³¨æ„æå–æ‰€æœ‰ç”ŸåŒ–æŒ‡æ ‡çš„å…·ä½“æ•°å€¼å’Œå•ä½
10. ä¿æŒç”Ÿå‘½ä½“å¾çš„æ ¼å¼ç»Ÿä¸€

è¯·ç›´æ¥è¿”å›JSONæ•°æ®ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚
ç¡®ä¿è¿”å›çš„JSONä½¿ç”¨ä¸­æ–‡å­—æ®µåï¼Œä¸ç¤ºä¾‹å®Œå…¨ä¸€è‡´ã€‚""".format(
            example_json=example_json,
            text=text
        )

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system", 
                    "content": "ä½ æ˜¯ä¸€ä¸ªåŒ»ç–—ä¿¡æ¯ç»“æ„åŒ–ä¸“å®¶ï¼Œæ“…é•¿ä»ç—…å†ä¸­æå–å…³é”®åŒ»ç–—ä¿¡æ¯å¹¶ç”Ÿæˆè§„èŒƒçš„JSONæ•°æ®ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ç¤ºä¾‹æ ¼å¼æå–ä¿¡æ¯ï¼Œä½¿ç”¨ä¸­æ–‡å­—æ®µåã€‚"
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            temperature=0.1
        )
        
        # è·å–å¹¶è§£æJSONå“åº”
        json_str = response.choices[0].message.content.strip()
        
        # æ¸…ç†JSONå­—ç¬¦ä¸²
        if json_str.startswith('```json'):
            json_str = json_str[7:]
        if json_str.endswith('```'):
            json_str = json_str[:-3]
        json_str = json_str.strip()
        
        # æ˜¾ç¤ºåŸå§‹JSONå­—ç¬¦ä¸²ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        st.write("AIè¿”å›çš„JSONå­—ç¬¦ä¸²ï¼š")
        st.code(json_str, language="json")
        
        # è§£æJSON
        data = json.loads(json_str)
        
        # åˆ é™¤_idå­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if '_id' in data:
            del data['_id']
        
        return data
        
    except Exception as e:
        st.error(f"ç»“æ„åŒ–æ•°æ®æå–é”™è¯¯: {str(e)}")
        st.error("åŸå§‹é”™è¯¯ï¼š" + str(e))
        return None

def get_database_commands(text: str) -> dict:
    """ä½¿ç”¨LLMåˆ†æç—…å†å†…å®¹å¹¶ç”Ÿæˆæ•°æ®åº“å‘½ä»¤"""
    try:
        client = OpenAI(
            api_key="sk-1pUmQlsIkgla3CuvKTgCrzDZ3r0pBxO608YJvIHCN18lvOrn",
            base_url="https://api.chatanywhere.tech/v1"
        )
        
        # æ˜¾ç¤ºæ­£åœ¨å¤„ç†çš„æ–‡æœ¬
        st.write("æ­£åœ¨åˆ†æçš„ç—…å†å†…å®¹ï¼š")
        st.code(text[:200] + "...")  # åªæ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦
        
        prompt = """è¯·åˆ†æä»¥ä¸‹åŒ»ç–—ç—…å†ï¼Œå¹¶ç”Ÿæˆæ•°æ®åº“å‘½ä»¤ã€‚ä¸¥æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹ï¼š

ç—…å†å†…å®¹ï¼š
{}

è¿”å›æ ¼å¼ï¼š
{{
    "relational_db": {{
        "create_tables": [
            "CREATE TABLE IF NOT EXISTS patients (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, gender TEXT, age INTEGER, admission_date DATE);",
            "CREATE TABLE IF NOT EXISTS diagnoses (id INTEGER PRIMARY KEY AUTOINCREMENT, patient_id INTEGER, diagnosis TEXT, FOREIGN KEY(patient_id) REFERENCES patients(id));"
        ],
        "insert_data": [
            "INSERT INTO patients (name, gender, age, admission_date) VALUES ('å¼ ä¸‰', 'ç”·', 45, '2024-01-01');",
            "INSERT INTO diagnoses (patient_id, diagnosis) VALUES (1, 'é«˜è¡€å‹');"
        ]
    }},
    "graph_db": {{
        "nodes": [
            {{
                "id": "patient_1",
                "type": "patient",
                "properties": {{
                    "name": "å¼ ä¸‰",
                    "age": 45,
                    "gender": "ç”·"
                }}
            }}
        ],
        "relationships": [
            {{
                "from_node": "patient_1",
                "to_node": "diagnosis_1",
                "type": "HAS_DIAGNOSIS",
                "properties": {{
                    "date": "2024-01-01"
                }}
            }}
        ]
    }}
}}""".format(text)

        # æ˜¾ç¤ºå‘é€ç»™LLMçš„æç¤ºè¯
        st.write("å‘é€ç»™AIçš„æç¤ºè¯ï¼š")
        st.code(prompt[:200] + "...")  # åªæ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system", 
                    "content": "ä½ æ˜¯ä¸€ä¸ªåŒ»ç–—æ•°æ®åº“ä¸“å®¶ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›æ•°æ®åº“å‘½ä»¤ï¼Œç¡®ä¿SQLè¯­å¥å’Œå›¾æ•°æ®åº“å‘½ä»¤éƒ½æ˜¯å®Œæ•´ä¸”å¯æ‰§è¡Œçš„ã€‚"
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            temperature=0.1  # é™ä½éšæœºæ€§
        )
        
        # è·å–å“åº”æ–‡æœ¬
        response_text = response.choices[0].message.content.strip()
        
        # æ˜¾ç¤ºåŸå“åº”
        st.write("AIçš„å§‹å“åº”ï¼š")
        st.code(response_text)
        
        # æ¸…ç†å“åº”æ–‡æœ¬
        if response_text.startswith('```json'):
            response_text = response_text[7:]
        if response_text.endswith('```'):
            response_text = response_text[:-3]
        response_text = response_text.strip()
        
        try:
            # å°è¯•è§£JSON
            commands = json.loads(response_text)
            
            # éªŒè¯JSONç»“æ„
            if not isinstance(commands, dict):
                raise ValueError("è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆçš„JSONå¯¹è±¡")
            if "relational_db" not in commands or "graph_db" not in commands:
                raise ValueError("JSONç¼ºå°‘å¿…è¦çš„é”®")
            
            # æ˜¾ç¤ºè§£æåçš„å‘½ä»¤
            st.write("è§£æåçš„æ•°æ®åº“å‘½ä»¤ï¼š")
            st.json(commands)
            
            return commands
        except json.JSONDecodeError as e:
            st.error(f"JSON: {str(e)}")
            st.error("ä½ç½®ï¼š" + str(e.pos))
            st.error("è¡Œå·ï¼š" + str(e.lineno))
            st.error("åˆ—å·ï¼š" + str(e.colno))
            return None
        except ValueError as e:
            st.error(f"æ•°æ®éªŒè¯é”™è¯¯: {str(e)}")
            return None
            
    except Exception as e:
        st.error(f"ç”Ÿæˆæ•°æ®åº“å‘½ä»¤å¤±è´¥: {str(e)}")
        st.error("åŸå§‹é”™è¯¯ï¼š" + str(e))  # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
        return None

def execute_database_commands(commands: dict):
    """æ‰§è¡Œæ•°æ®åº“å‘½ä»¤"""
    try:
        # æ‰§è¡Œå…³ç³»æ•°æ®åº“å‘½ä»¤
        conn = sqlite3.connect('medical_records.db')
        cursor = conn.cursor()
        
        st.write("åˆ›å»ºæ•°æ®è¡¨...")
        for create_command in commands['relational_db']['create_tables']:
            cursor.execute(create_command)
            st.write(f"âœ… æ‰§è¡ŒæˆåŠŸ: {create_command[:50]}...")
        
        st.write("æ’æ•°æ®...")
        for insert_command in commands['relational_db']['insert_data']:
            cursor.execute(insert_command)
            st.write(f"âœ… æ‰§è¡ŒæˆåŠŸ: {insert_command[:50]}...")
        
        conn.commit()
        conn.close()
        
        # åˆ›å»ºå›¾æ•°æ®åº“
        st.write("æ„å»ºçŸ¥è¯†è°±...")
        G = nx.Graph()
        
        # æ·»åŠ èŠ‚ç‚¹
        for node in commands['graph_db']['nodes']:
            G.add_node(node['id'], 
                      type=node['type'],
                      **node['properties'])
            st.write(f"âœ… æ·»åŠ èŠ‚ç‚¹: {node['id']}")
        
        # æ·»åŠ å…³ç³»
        for rel in commands['graph_db']['relationships']:
            G.add_edge(rel['from_node'],
                      rel['to_node'],
                      type=rel['type'],
                      **rel.get('properties', {}))
            st.write(f"âœ… æ·»åŠ å…³ç³»: {rel['from_node']} -> {rel['to_node']}")
        
        # ä¿å­˜å›¾
        nx.write_gexf(G, "medical_graph.gexf")
        st.success(f"âœ… çŸ¥è¯†å›¾è°±æ„å»ºæˆåŠŸï¼ŒåŒ…å« {len(G.nodes)} ä¸ªèŠ‚ç‚¹å’Œ {len(G.edges)} æ¡è¾¹")
        
        return True
    except Exception as e:
        st.error(f"æ‰§è¡Œæ•°æ®åº“å‘½ä»¤å¤±è´¥: {str(e)}")
        return False

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="åŒ»ç–— RAG ç³»ç»Ÿ", layout="wide")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'data_initialized' not in st.session_state:
    st.session_state.data_initialized = False
if 'file_chunks' not in st.session_state:
    st.session_state.file_chunks = {}
if 'file_indices' not in st.session_state:
    st.session_state.file_indices = {}
if 'structured_data' not in st.session_state:
    st.session_state.structured_data = {}

# PDFè§£æç±»
class MedicalRecordParser:
    def __init__(self, pdf_content):
        self.content = pdf_content
        self.parsed_data = self._parse_content()
    
    def _parse_content(self):
        data = {}
        try:
            # æ‰“å°PDFå®¹ç”¨äºè°ƒè¯•
            st.write("PDFå†…å®¹:", self.content)
            
            # æå–åŸºæœ¬ä¿¡æ¯ï¼Œæ·»åŠ é”™è¯¯ç†
            def safe_extract(pattern, text, default="æœªçŸ¥"):
                match = re.search(pattern, text)
                return match.group(1) if match else default
            
            # æå–åŸºæœ¬ä¿¡æ¯
            data['name'] = safe_extract(r'å§“å\s*([\u4e00-\u9fa5]+)', self.content)
            data['gender'] = safe_extract(r'æ€§åˆ«\s*([\u4e00-\u9fa5]+)', self.content)
            
            # æå–å¹´é¾„ï¼Œæ·»åŠ é”™è¯¯å¤„ç†
            age_match = re.search(r'å¹´é¾„\s*(\d+)å²', self.content)
            data['age'] = int(age_match.group(1)) if age_match else 0
            
            data['ethnicity'] = safe_extract(r'æ°‘æ—\s*([\u4e00-\u9fa5]+)', self.content)
            data['marriage'] = safe_extract(r'å©šå§»\s*([\u4e00-\u9fa5]+)', self.content)
            
            # æå–æ—¥æœŸï¼Œæ·»åŠ é”™è¯¯å¤„ç†
            admission_date = safe_extract(r'ä½é™¢æ—¥æœŸ\s*:(\d{4}\s*å¹´\d{1,2}æœˆ\d{1,2}æ—¥)', self.content)
            if admission_date != "æœªçŸ¥":
                data['admission_date'] = datetime.strptime(admission_date.replace(' ', ''), '%Yå¹´%mæœˆ%dæ—¥').strftime('%Y-%m-%d')
            else:
                data['admission_date'] = datetime.now().strftime('%Y-%m-%d')
            
            # æå–ä¸»è¯‰å’Œç—…
            data['chief_complaint'] = safe_extract(r'ä¸»\s*è¯‰\s*:(.*?)(?:ç°ç—…å²|$)', self.content)
            data['present_illness'] = safe_extract(r'ç°ç—…å²\s*:(.*?)(?:æ—¢å¾€å²|$)', self.content)
            data['past_history'] = safe_extract(r'æ—¢å¾€å²\s*:(.*?)(?:æ£€æŸ¥|$)', self.content)
            
            # æå–ç”Ÿå‘½ä½“å¾
            data['vital_signs'] = {
                'temperature': safe_extract_float(r'ä½“æ¸©\s*(\d+\.?\d*)\s*â„ƒ', self.content),
                'pulse': safe_extract_int(r'è„‰æ\s*(\d+)\s*æ¬¡/åˆ†', self.content),
                'breathing': safe_extract_int(r'å‘¼å¸\s*(\d+)\s*æ¬¡/åˆ†', self.content),
                'blood_pressure': safe_extract(r'è¡€å‹\s*(\d+/\d+)\s*mmHg', self.content)
            }
            
            # æå–ä½“æ ¼æ£€æŸ¥
            data['physical_exam'] = safe_extract(r'ä½“æ ¼æ£€æŸ¥\s*:(.*?)(?:è¾…åŠ©æ£€|$)', self.content)
            
            # æå–ç—‡çŠ¶ï¼ˆå¸¦è¯¦ç»†ä¿¡
            symptoms_text = safe_extract(r'ä¸»\s*è¯‰\s*:(.*?)(?:å…¥é™¢æ—¶æƒ…å†µ|$)', self.content)
            data['symptoms'] = []
            for symptom_match in re.finditer(r'([^ï¼Œã€‚ã€]+?)(?:æœ‰|å‡ºç°)([^ã€]+)', symptoms_text):
                data['symptoms'].append({
                    'symptom': symptom_match.group(1),
                    'description': symptom_match.group(2),
                    'onset_date': None  # å¯ä»¥è¿›ä¸€æ­¥æå–æ—¶é—´ä¿¡æ¯
                })
            
            # å–æ£€æŸ¥ç»“æœå¸¦å¼‚æ ‡è®°ï¼‰
            data['examinations'] = {}
            exam_patterns = {
                'å¤´é¢…MRI': r'å¤´é¢…\s*MRI\s*æç¤º(.*?)ã€‚',
                'åŠ¨æ€å¿ƒç”µå›¾': r'åŠ¨æ€å¿ƒç”µå›¾\s*:(.*?)ã€‚',
                'çœ¼éœ‡ç”µå›¾': r'çœ¼éœ‡ç”µå›¾æç¤º(.*?)ã€‚',
                'è¡€å¸¸è§„': r'è¡€å¸¸è§„[æ£€æŸ¥]*[:ï¼š](.*?)',
                'å¿ƒè„è¶…å£°': r'å¿ƒè„è¶…å£°[æ£€æŸ¥]*[:ï¼š](.*?)ã€‚'
            }
            for exam, pattern in exam_patterns.items():
                if match := re.search(pattern, self.content):
                    result = match.group(1).strip()
                    data['examinations'][exam] = {
                        'result': result,
                        'abnormal': bool(re.search(r'å¼‚å¸¸|é«˜|é™ä½|ä¸è¶³|è¿‡å¤š', result)),
                        'description': result
                    }
            
            # æå–æ²»ç–—ä¿¡æ¯
            treatment_text = safe_extract(r'æ²»ç–—ç»è¿‡\s*:(.*?)(?:å‡ºé™¢|$)', self.content)
            data['treatments'] = []
            for treatment_match in re.finditer(r'(ç»™äºˆ|ä½¿ç”¨)([^ã€‚ã€]+?)(?:æ²»ç–—|ç”¨è¯)', treatment_text):
                data['treatments'].append({
                    'treatment_type': 'è¯ç‰©æ²»ç–—',
                    'medication': treatment_match.group(2),
                    'dosage': None,  # å¯ä»¥è¿›ä¸€æ­¥æå–å‰‚é‡ä¿¡æ¯
                    'frequency': None  # å¯ä»¥è¿›ä¸€æ­¥æå–é¢‘ç‡ä¿¡æ¯
                })
            
            # æ‰“å°è§£æç»“æœç”¨äºè°ƒè¯•
            st.write("è§£æç»“æœ:", data)
            
            return data
        except Exception as e:
            st.error(f"æPDFå†…å®¹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            # è¿”å›é»˜æ•°æ®è€Œä¸æ˜¯å­—å…¸
            return {
                'name': 'æœªçŸ¥è€…',
                'gender': 'æœªçŸ¥',
                'age': 0,
                'ethnicity': 'æœªçŸ¥',
                'marriage': 'æœªçŸ¥',
                'admission_date': datetime.now().strftime('%Y-%m-%d'),
                'diagnoses': ['æœªçŸ¥æ–­'],
                'symptoms': ['æœªçŸ¥ç—‡çŠ¶'],
                'examinations': {'åŸºæœ¬æ£€æŸ¥': 'æœªè§å¼‚å¸¸'}
            }

# æ·»åŠ è¾…åŠ©å‡½
def safe_extract_float(pattern, text, default=0.0):
    """å®‰å…¨æå–æµ®ç‚¹æ•°"""
    match = re.search(pattern, text)
    try:
        return float(match.group(1)) if match else default
    except:
        return default

def safe_extract_int(pattern, text, default=0):
    """å®‰å…¨æå–æ•´æ•°"""
    match = re.search(pattern, text)
    try:
        return int(match.group(1)) if match else default
    except:
        return default

# æ·»åŠ æ¸…ç†æ•°æ®çš„å‡½æ•°
def clear_all_data():
    """æ¸…ç†æ‰€æœ‰æ•°æ®"""
    try:
        # æ¸…ç†å‘é‡æ•°æ®åº“
        st.write("æ¸…ç†å‘é‡æ•°æ®åº“...")
        st.session_state.file_chunks = {}
        st.session_state.file_indices = {}
        
        # æ¸…ç†session stateä¸­çš„ç»“æ„åŒ–æ•°æ®
        st.write("æ¸…ç†ç»“åŒ–æ•°æ®...")
        st.session_state.structured_data = {}
        st.session_state.mongodb_records = []
        
        # æ¸…ç†MongoDBä¸­çš„æ•°æ®ï¼ˆå¯é€‰ï¼‰
        # db = get_mongodb_connection()
        # if db:
        #     db.patients.delete_many({})
        
        st.success("âœ… æ‰€æœ‰æ•°æ®æ¸…ç†å®Œ")
        return True
    except Exception as e:
        st.error(f"æ¸…ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        return False

# ä¿®æ”¹æ•°æ®å¯¼å…¥å‡½æ•°
def import_medical_data(pdf_content):
    try:
        # é¦–å…ˆæµ‹è¯•MongoDBè¿æ¥
        st.write("æµ‹è¯•MongoDBè¿æ¥...")
        db = get_mongodb_connection()
        if db is None:
            st.error("MongoDBè¿æ¥å¤±è´¥ï¼Œç»ˆæ­¢å¯¼å…¥")
            return False
        
        # æ¸…ç†æ—§æ•°æ®
        st.write("å¼€å§‹æ¸…ç†æ—§æ•°æ®...")
        if not clear_all_data():
            st.error("æ¸…ç†æ—§æ•°æ®å¤±è´¥ï¼Œç»ˆæ­¢å¯¼å…¥")
            return False
        
        # ä½¿ç”¨LLMæå–ç»“æ„åŒ–æ•°æ®
        st.write("ä½¿ç”¨AIæå–ç»“æ„åŒ–æ•°æ®...")
        data = get_structured_data(pdf_content)
        if not data:
            st.error("ç»“æ„åŒ–æ•°æ®æå–å¤±è´¥")
            return False
        
        # æ·»åŠ å…ƒæ•°æ®
        data['metadata'] = {
            'import_time': datetime.now().isoformat(),
            'source_type': 'pdf',
            'last_updated': datetime.now().isoformat()
        }
        
        # ä¿å­˜åˆ°MongoDB
        st.write("ä¿å­˜ç»“æ„åŒ–æ•°æ®åˆ°MongoDB...")
        try:
            # ä¿å­˜åˆ°patientsé›†åˆ
            result = db.patients.insert_one(data)
            st.write(f" æ•°æ®ä¿å­˜åˆ°MongoDB (ID: {result.inserted_id})")
            
            # ä¿å­˜IDåˆ°session stateä»¥ä¾¿åç»­æŸ¥è¯¢
            if 'mongodb_records' not in st.session_state:
                st.session_state.mongodb_records = []
            st.session_state.mongodb_records.append(str(result.inserted_id))
            
            # åŒæ—¶ä¿å­˜åˆ°session stateç”¨äºå³æ—¶æŸ¥è¯¢
            st.session_state.structured_data = data
            st.write("âœ… ç»“æ„åŒ–æ•°æ®ä¿å­˜æˆåŠŸ")
        except Exception as e:
            st.error(f"MongoDBæ’å…¥æ•°æ®è¯¯: {str(e)}")
            return False
        
        # å‘é‡åŒ–æ–‡æ¡£
        st.write("å¼€å§‹å‘é‡æ–‡æ¡£...")
        chunks, index = vectorize_document(pdf_content)
        # ä½¿ç”¨æ‚£è€…å§“åä½œä¸ºæ–‡ä»¶å
        file_name = f"{data.get('æ‚£è€…å§“å', 'æœªçŸ¥æ‚£è€…')}çš„ç—…å†"
        st.session_state.file_chunks[file_name] = chunks
        st.session_state.file_indices[file_name] = index
        st.write(f"âœ… å‘é‡åŒ–æˆåŠŸï¼Œå…±ç”Ÿæˆ {len(chunks)} ä¸ªæ–‡æ¡£å—")
        
        return True
    except Exception as e:
        st.error(f"æ•°æ®å¯¼å…¥è¯¯: {str(e)}")
        return False

# æœç´¢æ•°
def get_vector_search_results(query: str) -> list:
    try:
        results = []
        for file_name, chunks in st.session_state.file_chunks.items():
            index = st.session_state.file_indices[file_name]
            chunk_results = search_similar(query, index, chunks)
            results.extend([f"{file_name}: {chunk}" for chunk in chunk_results])
        return results
    except Exception as e:
        st.error(f"å‘é‡æœç´¢é”™è¯¯: {str(e)}")
        return []

def get_rdb_search_results(query: str) -> list:
    try:
        conn = sqlite3.connect('medical_records.db')
        cursor = conn.cursor()
        cursor.execute("""
            SELECT p.name, d.diagnosis 
            FROM patients p 
            JOIN diagnoses d ON p.id = d.patient_id 
            WHERE d.diagnosis LIKE ?
        """, (f"%{query}%",))
        results = cursor.fetchall()
        conn.close()
        return [f"{name}: {diagnosis}" for name, diagnosis in results]
    except Exception as e:
        st.error(f"æ®åº“æœç´¢é”™è¯¯: {str(e)}")
        return []

def generate_graph_query(query: str) -> dict:
    """ä½¿ç”¨LLMç”Ÿæˆå›¾æ•°æ®åº“æŸ¥è¯¢æ¡ä»¶"""
    try:
        st.write("å¼€å§‹åˆ›å»ºOpenAIå®¢æˆ·ç«¯...")
        client = OpenAI(
            api_key="sk-1pUmQlsIkgla3CuvKTgCrzDZ3r0pBxO608YJvIHCN18lvOrn",
            base_url="https://api.chatanywhere.tech/v1",
            timeout=60
        )
        st.write("âœ… OpenAIå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        
        # è¯»å–å›¾æ•°æ®åº“çš„ç»“æ„ä¿¡æ¯
        G = nx.read_gexf("medical_graph.gexf")
        
        # è·å–å›¾çš„åŸºæœ¬ä¿¡æ¯
        graph_info = {
            "node_types": list(set(nx.get_node_attributes(G, 'type').values())),
            "relationships": list(set(nx.get_edge_attributes(G, 'relationship').values())),
            "nodes_sample": {
                node: data for node, data in list(G.nodes(data=True))[:5]
            },
            "edges_sample": {
                f"{u}->{v}": data for u, v, data in list(G.edges(data=True))[:5]
            }
        }
        
        prompt = f"""è¯·æ ¹æ®é—®é¢˜å’Œå›¾æ•°æ®åº“ç»“æ„ç”Ÿæˆå›¾æ•°æ®åº“æŸ¥è¯¢æ¡ä»¶ã€‚

å›¾æ•°æ®åº“ç»“æ„ï¼š
èŠ‚ç‚¹ç±»å‹: {graph_info["node_types"]}
å…³ç³»ç±»å‹: {graph_info["relationships"]}
èŠ‚ç‚¹ç¤ºä¾‹: {json.dumps(graph_info["nodes_sample"], ensure_ascii=False, indent=2)}
å…³ç³»ç¤ºä¾‹: {json.dumps(graph_info["edges_sample"], ensure_ascii=False, indent=2)}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·ç”Ÿä¸€ä¸ªåŒ…å«æŸ¥è¯¢æ¡ä»¶çš„å­—å…¸ï¼Œç¤ºä¾‹æ ¼å¼ï¼š

1. æŸ¥è¯¢æ‚£è€…çš„ä¸»è¯‰ï¼š
{{
    "start_node": {{"type": "patient", "name": "ä»é—®é¢˜ä¸­æå–çš„æ‚£è€…å§“å"}},
    "relationship": "complains_of",
    "end_node": {{"type": "chief_complaint"}},
    "return": ["end_node.content"]
}}

2. æŸ¥è¯¢æ‚£è€…çš„ç”Ÿå‘½ä½“å¾ï¼š
{{
    "start_node": {{"type": "patient", "name": "ä»é—®é¢˜ä¸­æå–çš„æ‚£è€…å§“å"}},
    "relationship": "has_vital_sign",
    "end_node": {{"type": "vital_sign"}},
    "return": ["end_node.name", "end_node.value"]
}}

3. æŸ¥è¯¢æ‚£è€…çš„ç”ŸåŒ–æŒ‡æ ‡ï¼š
{{
    "start_node": {{"type": "patient", "name": "ä»é—®é¢˜ä¸­æå–çš„æ‚£è€…å§“å"}},
    "relationship": "has_test_result",
    "end_node": {{"type": "biochemical_test"}},
    "return": ["end_node.name", "end_node.value"]
}}

æ³¨æ„ï¼š
1. ä»ç”¨æˆ·é—®é¢˜ä¸­æå–æ­£ç¡®çš„æ‚£è€…å§“å
2. ä½¿ç”¨æ­£ç¡®çš„èŠ‚ç‚¹ç±»å‹å’Œå…³ç³»ç±»å‹
3. ä½¿ç”¨æ­£ç¡®çš„å±æ€§åç§°
4. æŒ‡å®šè¦è¿”å›çš„å…·ä½“å±æ€§

è¯·ç›´æ¥è¿”å›æŸ¥è¯¢æ¡ä»¶çš„JSONå­—ç¬¦ä¸²ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹ã€‚"""

        st.write("ğŸ”„ æ­£åœ¨è°ƒç”¨OpenAI API...")
        response = client.chat.completions.create(
            model="gpt-4o-mini-2024-07-18",
            messages=[
                {
                    "role": "system", 
                    "content": "ä½ æ˜¯ä¸€ä¸ªå›¾æ•°æ®åº“æŸ¥è¯¢ä¸“å®¶ã€‚æ ¹æ®å®é™…çš„æ•°åº“ç»“æ„ç”Ÿæˆç²¾ç¡®çš„æŸ¥è¯¢æ¡ä»¶ã€‚"
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            temperature=0.1
        )
        st.write("âœ… OpenAI APIè°ƒç”¨æˆåŠŸ")
        
        # è·å–å“åº”æ–‡æœ¬å¹¶æ¸…ç†
        query_str = response.choices[0].message.content.strip()
        st.write("åŸå§‹å“åº”æ–‡æœ¬ï¼š", query_str)
        
        if query_str.startswith('```json'):
            query_str = query_str[7:]
        if query_str.endswith('```'):
            query_str = query_str[:-3]
        query_str = query_str.strip()
        
        st.write("æ¸…ç†åçš„JSONå­—ç¬¦ä¸²ï¼š", query_str)
        
        # æ˜¾ç¤ºç”Ÿæˆçš„æŸ¥è¯¢æ¡ä»¶
        st.write("ç”Ÿæˆçš„å›¾æ•°æ®åº“æŸ¥è¯¢æ¡ä»¶ï¼š")
        st.code(query_str, language="json")
        
        return json.loads(query_str)
        
    except Exception as e:
        st.error(f"ç”Ÿæˆå›¾æ•°æ®åº“æŸ¥è¯¢æ¡ä»¶é”™è¯¯: {str(e)}")
        st.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        st.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        return None

def get_graph_search_results(query: str) -> list:
    """ä»å›¾æ•°æ®åº“ä¸­æœç´¢ç›¸å…³ä¿¡æ¯"""
    try:
        # ä½¿ç”¨LLMç”ŸæˆæŸ¥è¯¢æ¡ä»¶
        query_obj = generate_graph_query(query)
        if not query_obj:
            return []
        
        G = nx.read_gexf("medical_graph.gexf")
        results = []
        
        # æ ¹æ®æŸ¥è¯¢æ¡ä»¶æ‰§è¡Œæœç´¢
        start_nodes = [node for node, data in G.nodes(data=True)
                      if data.get('type') == query_obj["start_node"]["type"] and 
                         node == query_obj["start_node"]["name"]]
        
        for start_node in start_nodes:
            # è·å–æ‰€æœ‰é‚»å±…èŠ‚ç‚¹
            for neighbor in G.neighbors(start_node):
                edge_data = G.get_edge_data(start_node, neighbor)
                neighbor_data = G.nodes[neighbor]
                
                # æ£€æŸ¥å…³ç³»ç±»å‹å’Œç»ˆç‚¹èŠ‚ç‚¹ç±»å‹æ˜¯å¦åŒ¹é…
                if (edge_data.get("relationship") == query_obj["relationship"] and
                    neighbor_data.get('type') == query_obj["end_node"]["type"]):
                    
                    # æ„å»ºç»“æœ
                    result = []
                    for attr in query_obj["return"]:
                        node_type, attr_name = attr.split(".")
                        if node_type == "end_node":
                            result.append(f"{attr_name}: {neighbor_data.get(attr_name, '')}")
                    
                    results.append(f"{start_node} -> {edge_data.get('relationship')} -> {' | '.join(result)}")
        
        return results
    except Exception as e:
        st.error(f"å›¾æ•°æ®åº“æœç´¢é”™è¯¯: {str(e)}")
        return []

def generate_mongodb_query(query: str) -> dict:
    """ä½¿ç”¨LLMç”ŸæˆMongoDBæŸ¥è¯¢æ¡ä»¶å’ŒæŠ•å½±"""
    try:
        st.write("å¼€å§‹åˆ›å»ºOpenAIå®¢ç«¯...")
        client = OpenAI(
            api_key="sk-1pUmQlsIkgla3CuvKTgCrzDZ3r0pBxO608YJvIHCN18lvOrn",
            base_url="https://api.chatanywhere.tech/v1",
            timeout=60
        )
        st.write("âœ… OpenAIå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        
        # è¯»å–ç¤ºä¾‹JSONç»“æ„
        st.write("è¯»å–JSONæ¨¡æ¿...")
        with open('get_inf.json', 'r', encoding='utf-8') as f:
            schema = json.load(f)
        st.write("âœ… JSONæ¨¡æ¿è¯»å–æˆåŠŸ")
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªMongoDBæŸ¥è¯¢ä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹é—®é¢˜å’Œæ•°ç»“æ„ç”ŸæˆMongoDBæŸ¥è¯¢æ¡ä»¶ã€‚

æ®ç»“æ„ï¼š
{json.dumps(schema, ensure_ascii=False, indent=2)}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·ç”Ÿæˆä¸€ä¸ªMongoDBæŸ¥è¯¢å¯¹è±¡ï¼Œå¿…é¡»åŒ…å«queryå’Œprojectionä¸¤å­—æ®µã€‚ç¤ºä¾‹æ ¼å¼ï¼š

{{
    "query": {{"æ‚£è€…å§“å": "é©¬æŸæŸ"}},
    "projection": {{"æ‚£è€…å§“å": 1, "ç”Ÿå‘½ä½“å¾.è¡€å‹": 1, "_id": 0}}
}}

æ³¨æ„ï¼š
1. å¿…é¡»è¿”å›åˆæ³•çš„JSONæ ¼å¼
2. å¿…é¡»åŒ…å«queryå’Œprojectionä¸¤ä¸ªå­—æ®µ
3. ä½¿ç”¨åŒå¼•å·è€Œä¸æ˜¯å•å¼•
4. å­—æ®µåå¿…é¡»ä¸æ•°æ®ç»“æ„ä¸­çš„å®Œå…¨åŒ¹é…
5. ä¸è¦è¿”å›ä»»ä½•å…¶ä»–å†…å®¹ï¼Œåªè¿”å›JSONå¯¹è±¡

è¯·ç›´æ¥è¿”å›æŸ¥è¯¢å¯¹è±¡ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–è¯´æ˜ã€‚"""

        st.write("ğŸ”„ æ­£åœ¨è°ƒç”¨OpenAI API...")
        response = client.chat.completions.create(
            model="gpt-4o-mini-2024-07-18",  # ä¿®æ”¹è¿™é‡Œ
            messages=[
                {
                    "role": "system", 
                    "content": "ä½ æ˜¯ä¸€ä¸ªMongoDBæŸ¥è¯¢ä¸“å®¶ã€‚è¯·åªè¿”å›JSONæ ¼å¼çš„æŸ¥è¯¢å¯¹è±¡ï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–å†…å®¹ã€‚"
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            temperature=0.1
        )
        st.write("âœ… OpenAI APIè°ƒç”¨æˆ")
        
        # è·å–å“åº”æ–‡æœ¬å¹¶æ¸…ç†
        query_str = response.choices[0].message.content.strip()
        st.write("åŸå§‹å“åº”æ–‡æœ¬ï¼š", query_str)
        
        # æ¸…ç†JSONå­—ç¬¦ä¸²
        if query_str.startswith('```json'):
            query_str = query_str[7:]
        if query_str.endswith('```'):
            query_str = query_str[:-3]
        query_str = query_str.strip()
        
        st.write("æ¸…ç†åçš„JSONå­—ç¬¦ä¸²ï¼š", query_str)
        
        # æ˜¾ç¤ºç”Ÿæˆçš„æŸ¥è¯¢æ¡ä»¶
        st.write("ç”Ÿæˆçš„MongoDBæŸ¥è¯¢æ¡ä»¶ï¼š")
        st.code(query_str, language="json")
        
        return json.loads(query_str)
        
    except Exception as e:
        st.error(f"ç”ŸæˆæŸ¥è¯¢æ¡ä»¶é”™è¯¯: {str(e)}")
        st.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        st.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        return None

def get_structured_search_results(query: str) -> list:
    """ä»MongoDBä¸­æœç´¢ç›¸å…³ä¿¡æ¯"""
    try:
        db = get_mongodb_connection()
        if db is None:
            return []
        
        # ä½¿ç”¨LLMç”ŸæˆæŸ¥è¯¢æ¡ä»¶å’ŒæŠ•å½±
        query_obj = generate_mongodb_query(query)
        if not query_obj:
            return []
        
        # æ‰§è¡ŒæŸ¥è¯¢ï¼Œä½¿ç”¨ç”Ÿæˆçš„æŸ¥è¯¢æ¡ä»¶å’ŒæŠ•å½±
        docs = list(db.patients.find(query_obj["query"], query_obj["projection"]))
        st.write(f"æ‰¾åˆ° {len(docs)} æ¡è®°å½•")
        
        results = []
        for doc in docs:
            # ç›´æ¥è¿”å›æŸ¥è¯¢åˆ°çš„å­—æ®µå†…å®¹
            for field, value in doc.items():
                if field != '_id' and field != 'metadata':  # æ’é™¤ç‰¹æ®Šå­—æ®µ
                    if isinstance(value, list):
                        # å¤„ç†æ•°ç»„ç±»å‹çš„å­—æ®µ
                        results.append(f"æ‚£è€… {doc.get('æ‚£è€…å§“å', 'æœªçŸ¥')} çš„{field}ï¼š")
                        for item in value:
                            results.append(f"- {item}")
                    elif isinstance(value, dict):
                        # å¤„ç†å­—å…¸ç±»å‹çš„å­—æ®µ
                        results.append(f"æ‚£è€… {doc.get('æ‚£è€…å§“å', 'æœªçŸ¥')} çš„{field}ï¼š")
                        for k, v in value.items():
                            results.append(f"- {k}: {v}")
                    else:
                        # å¤„ç†æ™®é€šå­—æ®µ
                        results.append(f"æ‚£è€… {doc.get('æ‚£å§“å', 'æœªçŸ¥')} çš„{field}æ˜¯: {value}")
        
        return results
    except Exception as e:
        st.error(f"MongoDBæœç´¢é”™è¯¯: {str(e)}")
        return []

# ä¿®LLMå“åº”å‡½æ•°
def get_llm_response(query: str, search_results: dict) -> str:
    try:
        client = OpenAI(
            api_key="sk-2D0EZSwcWUcD4c2K59353b7214854bBd8f35Ac131564EfBa",
            base_url="https://free.gpt.ge/v1"
        )
        
        prompt = f"""è¯·åŸºäºä»¥ä¸‹ç›¸å…³å†…å®¹å›ç­”é—®é¢˜ï¼š

ç”¨æˆ·é—®é¢˜: {query}

ç›¸å†…å®¹:
{search_results}

è¯·æ³¨æ„ï¼š
1. åªä½¿ç”¨æä¾›çš„ç›¸å…³å†…å®¹å›ç­”é—®é¢˜
2. å¦‚æœç›¸å…³å†…å®¹ä¸­æ²¡æœ‰ç­”æ¡ˆï¼Œè¯·æ˜ç¡®è¯´æ˜
3. ä¸è¦æ·»åŠ ä»»ä½•ä¸åœ¨ç›¸å…³å†…å®¹ä¸­çš„ä¿¡æ¯
4. ä¿æŒå›ç­”çš„å‡†ç¡®æ€§å’Œå®¢è§‚æ€§"""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system", 
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—åŠ©æ‰‹ï¼Œæ“…é•¿è§£è¯»åŒ»ç–—ä¿¡æ¯å¹¶æä¾›å‡†ç¡®çš„è§£ç­”ã€‚"
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            temperature=0.1
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"LLMå“åº”é”™è¯¯: {str(e)}")
        return "æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°é”™è¯¯ã€‚"

# é¡µé¢æ ‡é¢˜å’Œå¼€å‘è€…ä¿¡æ¯
st.title("ğŸ¥ åŒ»ç–— RAG ç³»ç»Ÿ")
st.markdown("""
<div style='text-align: right; color: gray; padding: 0px 0px 20px 0px;'>
    <p>Developed by Huaiyuan Tan</p>
</div>
""", unsafe_allow_html=True)

# ä¿®æ”¹ä¾§è¾¹æ éƒ¨åˆ†
with st.sidebar:
    st.header("ç³»ç»Ÿè®¾ç½®")
    
    # æ˜¾ç¤ºæ•°æ®çŠ¶æ€
    if check_data_initialized():
        st.success("âœ… æ•°æ®åº“ä¸­å·²æœ‰æ•°æ®")
    else:
        st.warning("âš ï¸ æ•°æ®åº“ä¸­æš‚æ— æ•°æ®")
    
    # æ•°æ®å¯¼å…¥éƒ¨åˆ†
    st.subheader("æ•°æ®å¯¼å…¥")
    import_db = st.selectbox(
        "é€‰æ‹©è¦å¯¼å…¥çš„æ•°æ®åº“",
        ["å‘é‡æ•°æ®åº“", "MongoDB", "å›¾æ•°æ®åº“", "å…¨éƒ¨å¯¼å…¥"]
    )
    
    if import_db in ["å‘é‡æ•°æ®åº“", "MongoDB", "å…¨éƒ¨å¯¼å…¥"]:
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ ç—…å†PDFæ–‡ä»¶ï¼ˆå¯å¤šé€‰ï¼‰", 
            type=['pdf'],
            accept_multiple_files=True  # å¯ç”¨å¤šæ–‡ä»¶ä¸Šä¼ 
        )
        
        if uploaded_files:
            st.write(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼š")
            for file in uploaded_files:
                st.write(f"- {file.name}")
            
            if st.button("å¯¼å…¥æ•°æ®"):
                with st.spinner("æ­£åœ¨å¯¼å…¥æ•°æ®..."):
                    success = True
                    
                    for uploaded_file in uploaded_files:
                        st.write(f"æ­£åœ¨å¤„ç†æ–‡ä»¶ï¼š{uploaded_file.name}")
                        
                        # è¯»å–PDFå†…å®¹
                        with pdfplumber.open(uploaded_file) as pdf:
                            pdf_content = ""
                            for page in pdf.pages:
                                pdf_content += page.extract_text()
                        
                        if import_db in ["å‘é‡æ•°æ®åº“", "å…¨éƒ¨å¯¼å…¥"]:
                            st.write(f"å¼€å§‹å¯¼å…¥å‘é‡æ•°æ®åº“ï¼š{uploaded_file.name}")
                            try:
                                # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºå”¯ä¸€æ ‡è¯†
                                file_name = uploaded_file.name.replace('.pdf', '')
                                chunks, index = vectorize_document(pdf_content, file_name)
                                if chunks and index:
                                    st.success(f"âœ… å‘é‡æ•°æ®åº“å¯¼å…¥æˆåŠŸï¼Œæ–‡æ¡£ '{file_name}' å…±ç”Ÿæˆ {len(chunks)} ä¸ªæ–‡æ¡£å—")
                                else:
                                    st.error(f"âŒ æ–‡æ¡£ '{file_name}' å¯¼å…¥å¤±è´¥")
                                    success = False
                            except Exception as e:
                                st.error(f"å‘é‡æ•°æ®åº“å¯¼å…¥å¤±è´¥: {str(e)}")
                                success = False
                        
                        if import_db in ["MongoDB", "å…¨éƒ¨å¯¼å…¥"]:
                            st.write(f"å¼€å§‹å¯¼å…¥MongoDBï¼š{uploaded_file.name}")
                            # [MongoDBå¯¼å…¥ä»£ç ä¿æŒä¸å˜...]
                    
                    if success:
                        st.success(f"âœ… æ‰€æœ‰ä»¶å¯¼å…¥å®Œæˆ")
                        st.rerun()
                    else:
                        st.error("éƒ¨åˆ†æ–‡ä»¶å¯¼å…¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        else:
            st.warning("è¯·å…ˆä¸Šä¼ PDFæ–‡ä»¶")
    
    elif import_db == "å›¾æ•°æ®åº“":
        if st.button("ä»MongoDBæ„å»ºå›¾æ•°æ®åº“"):
            # [å›¾æ•°æ®åº“æ„å»ºä»£ç ä¿æŒä¸å˜...]
            pass

# åœ¨ä¾§è¾¹æ æ·»åŠ æ•°æ®åº“å†…å®¹çœ‹åŠŸèƒ½
with st.sidebar:
    st.header("æ•°æ®åº“å†…å®¹æŸ¥çœ‹")
    view_db = st.selectbox(
        "é€‰æ‹©è¦æŸ¥çœ‹çš„æ•°æ®åº“",
        ["å‘é‡æ•°æ®åº“", "MongoDB", "å›¾æ•°æ®åº“"]
    )
    
    if st.button("æŸ¥çœ‹æ•°æ®"):
        if view_db == "å‘é‡æ•°æ®åº“":
            st.write("ğŸ“š å‘é‡æ•°æ®åº“å†…å®¹ï¼š")
            try:
                # åˆå§‹åŒ– Pinecone
                index = init_pinecone()
                if index:
                    # è·å–æ‰€æœ‰å‘é‡
                    stats = index.describe_index_stats()
                    total_vectors = stats.total_vector_count
                    
                    if total_vectors > 0:
                        st.write(f"æ€»å‘é‡æ•°é‡ï¼š{total_vectors}")
                        
                        # è·å–æ‰€æœ‰å‘é‡çš„å…ƒæ•°æ®
                        # ä½¿ç”¨ç©ºæŸ¥è¯¢è·å–æ‰€æœ‰å‘é‡
                        results = index.query(
                            vector=[0] * 384,  # ä½¿ç”¨é›¶å‘é‡ä½œä¸ºæŸ¥è¯¢å‘é‡
                            top_k=total_vectors,  # è·å–æ‰€æœ‰å‘é‡
                            include_metadata=True
                        )
                        
                        # æŒ‰æ–‡ä»¶åç»„ç»‡æ˜¾ç¤º
                        files = {}
                        for match in results['matches']:
                            file_name = match['metadata'].get('original_file_name', 'æœªçŸ¥æ–‡ä»¶')
                            if file_name not in files:
                                files[file_name] = []
                            files[file_name].append(match['metadata'].get('text', ''))
                        
                        # æ˜¾ç¤ºæ¯ä¸ªæ–‡ä»¶çš„å†…å®¹
                        for file_name, chunks in files.items():
                            with st.expander(f"æ–‡æ¡£ï¼š{file_name}"):
                                for i, chunk in enumerate(chunks):
                                    st.write(f"ç‰‡æ®µ {i+1}:")
                                    st.info(chunk)
                    else:
                        st.warning("å‘é‡æ•°æ®åº“ä¸­æš‚æ— æ•°æ®")
            except Exception as e:
                st.error(f"è¯»å–å‘é‡æ•°æ®åº“é”™è¯¯: {str(e)}")
                st.warning("å‘é‡æ•°æ®åº“ä¸­æš‚æ— æ•°æ®")
        
        elif view_db == "MongoDB":
            st.write("ğŸ“Š MongoDBå†…å®¹ï¼š")
            db = get_mongodb_connection()
            if db is not None:
                try:
                    docs = list(db.patients.find())
                    if docs:
                        for doc in docs:
                            with st.expander(f"æ‚£è€…ï¼š{doc.get('æ‚£è€…å§“å', 'æœªçŸ¥æ‚£è€…')}"):
                                # åŸºæœ¬ä¿¡æ¯
                                st.write("ğŸ‘¤ åŸºæœ¬ä¿¡æ¯ï¼š")
                                for key in ['æ€§åˆ«', 'å¹´é¾„', 'æ°‘æ—', 'èŒä¸š', 'å©šå§»çŠ¶å†µ', 'å…¥é™¢æ—¥æœŸ', 'å‡ºé™¢æ—¥æœŸ']:
                                    if key in doc:
                                        st.write(f"{key}: {doc[key]}")
                                
                                # ä¸»è¯‰å’Œç°ç—…å²
                                if 'ä¸»è¯‰' in doc:
                                    st.write("ğŸ” ä¸»è¯‰ï¼š", doc['ä¸»è¯‰'])
                                if 'ç°ç—…å²' in doc:
                                    st.write("ğŸ“ ç°ç—…å²ï¼š")
                                    for item in doc['ç°ç—…å²']:
                                        st.write(f"- {item}")
                                
                                # è¯Šæ–­ä¿¡æ¯
                                if 'å…¥é™¢è¯Šæ–­' in doc:
                                    st.write("ğŸ¥ å…¥é™¢è¯Šæ–­ï¼š")
                                    for diag in doc['å…¥é™¢è¯Šæ–­']:
                                        st.write(f"- {diag}")
                                if 'å‡ºé™¢è¯Šæ–­' in doc:
                                    st.write("ğŸ¥ å‡ºé™¢è¯Šæ–­ï¼š")
                                    for diag in doc['å‡ºé™¢è¯Šæ–­']:
                                        st.write(f"- {diag}")
                                
                                # ç”Ÿå‘½ä½“å¾
                                if 'ç”Ÿå‘½ä½“å¾' in doc:
                                    st.write("ğŸ’“ ç”Ÿå‘½ä½“å¾ï¼š")
                                    for key, value in doc['ç”Ÿå‘½ä½“å¾'].items():
                                        st.write(f"{key}: {value}")
                                
                                # ç”ŸåŒ–æŒ‡æ ‡
                                if 'ç”ŸåŒ–æŒ‡æ ‡' in doc:
                                    st.write("ğŸ”¬ ç”ŸåŒ–æŒ‡æ ‡ï¼š")
                                    for key, value in doc['ç”ŸåŒ–æŒ‡æ ‡'].items():
                                        st.write(f"{key}: {value}")
                                
                                # æ²»ç–—ç»è¿‡
                                if 'è¯Šç–—ç»è¿‡' in doc:
                                    st.write("ğŸ’Š è¯Šç–—ç»è¿‡ï¼š", doc['è¯Šç–—ç»è¿‡'])
                                
                                # å‡ºé™¢åŒ»å˜±
                                if 'å‡ºé™¢åŒ»å˜±' in doc:
                                    st.write("ğŸ“‹ å‡ºé™¢åŒ»å˜±ï¼š")
                                    for advice in doc['å‡ºé™¢åŒ»å˜±']:
                                        st.write(f"- {advice}")
                    else:
                        st.warning("MongoDBä¸­æš‚æ— æ•°æ®")
                except Exception as e:
                    st.error(f"æŸ¥è¯¢MongoDBé”™è¯¯: {str(e)}")
                    st.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                    st.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            else:
                st.error("MongoDBè¿æ¥å¤±è´¥")
        
        elif view_db == "å›¾æ•°æ®åº“":
            st.write("ğŸ•¸ï¸ å›¾æ•°æ®åº“å†…å®¹ï¼š")
            try:
                G = nx.read_gexf("medical_graph.gexf")
                
                # æ˜¾ç¤ºèŠ‚ç‚¹ä¿¡æ¯
                with st.expander("èŠ‚ç‚¹ä¿¡æ¯"):
                    st.write("æ€»èŠ‚ç‚¹æ•°ï¼š", len(G.nodes))
                    for node, data in G.nodes(data=True):
                        st.write(f"èŠ‚ç‚¹ï¼š{node}")
                        st.write(f"ç±»å‹ï¼š{data.get('type', 'æœªçŸ¥')}")
                        for key, value in data.items():
                            if key != 'type':
                                st.write(f"{key}: {value}")
                        st.write("---")
                
                # æ˜¾ç¤ºå…³ç³»ä¿¡æ¯
                with st.expander("å…³ç³»ä¿¡æ¯"):
                    st.write("æ€»å…³ç³»æ•°ï¼š", len(G.edges))
                    for u, v, data in G.edges(data=True):
                        st.write(f"å…³ç³»ï¼š{u} -> {v}")
                        st.write(f"ç±»å‹ï¼š{data.get('relationship', 'æœªçŸ¥')}")
                        for key, value in data.items():
                            if key != 'relationship':
                                st.write(f"{key}: {value}")
                        st.write("---")
            except Exception as e:
                st.error(f"è¯»å–å›¾æ•°æ®åº“é”™è¯¯: {str(e)}")
                st.warning("å›¾æ•°æ®åº“ä¸­æš‚æ— æ•°æ®")

# ä½¿ç”¨è¡¨å•åŒ…è£…æœç´¢éƒ¨åˆ†
search_form = st.form(key="search_form", clear_on_submit=False)
with search_form:
    # æ£€ç´¢æ–¹å¼é€‰æ‹©
    search_type = st.selectbox(
        "é€‰æ‹©æ£€ç´¢æ–¹å¼",
        ["å‘é‡æ•°æ®åº“", "MongoDB", "å›¾æ•°æ®åº“", "æ··åˆæ£€ç´¢"],
        help="é€‰æ‹©å•ä¸€æ•°æ®åº“æ£€ç´¢æˆ–æ··åˆæ£€ç´¢æ¨¡å¼"
    )
    
    # æŸ¥
    query = st.text_input("è¯·è¾“å…¥çš„é—®é¢˜ï¼š")
    
    # æäº¤é’®
    submit_button = st.form_submit_button("æœç´¢å¹¶ç”Ÿæˆç­”æ¡ˆ")

# åœ¨è¡¨å•å¤–å¤„ç†æœç´¢ç»“æœ
if submit_button:
    if not check_data_initialized():
        st.warning("æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®ï¼Œè¯·å…ˆå¯¼å…¥æ•°æ®ï¼")
    else:
        with st.spinner("æ­£åœ¨å¤„ç†..."):
            search_results = {}
            
            # æ ¹æ®é€‰æ‹©çš„æ£€ç´¢æ–¹å¼æ‰§è¡Œç›¸åº”çš„æœç´¢
            if search_type == "å‘é‡æ•°æ®åº“":
                # ä½¿ç”¨ vector_store.py ä¸­çš„å‡½æ•°è¿›è¡Œå‘é‡æœç´¢
                from vector_store import get_vector_search_results
                vector_results = get_vector_search_results(query)
                search_results = {
                    "vector": vector_results,
                    "structured": [],
                    "graph": []
                }
                # æ˜¾ç¤ºç»“æœ
                st.write("ğŸ” å‘é‡æœç´¢ç»“æœ:")
                with st.expander("å‘é‡æœç´¢è¯¦æƒ…", expanded=True):
                    if vector_results:
                        for result in vector_results:
                            st.info(result)
                    else:
                        st.write("æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
                        st.write("å¯èƒ½çš„åŸå› ï¼š")
                        st.write("1. ç›¸ä¼¼åº¦åˆ†æ•°ä½äºé˜ˆå€¼")
                        st.write("2. æŸ¥è¯¢å‘é‡ä¸æ–‡æ¡£å‘é‡å·®å¼‚è¾ƒå¤§")
                        st.write("3. æ•°æ®åº“ä¸­æ²¡æœ‰ç›¸å…³å†…å®¹")
                    
            elif search_type == "MongoDB":
                mongodb_results = get_structured_search_results(query)
                search_results = {
                    "vector": [],
                    "structured": mongodb_results,
                    "graph": []
                }
                # æ˜¾ç¤ºç»“æœ
                st.write("ğŸ“Š MongoDBæœç´¢ç»“æœ:")
                if mongodb_results:
                    for result in mongodb_results:
                        st.info(result)
                else:
                    st.write("æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
                    
            elif search_type == "å›¾æ•°æ®åº“":
                graph_results = get_graph_search_results(query)
                search_results = {
                    "vector": [],
                    "structured": [],
                    "graph": graph_results
                }
                # æ˜¾ç¤ºç»“æœ
                st.write("ğŸ•¸ï¸ å›¾æ•°æ®åº“æœç´¢ç»“æœ:")
                if graph_results:
                    for result in graph_results:
                        st.info(result)
                else:
                    st.write("æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
                    
            else:  # æ··åˆæ£€ç´¢
                # ä½¿ç”¨ vector_store.py ä¸­çš„å‡½æ•°è¿›è¡Œå‘é‡æœç´¢
                from vector_store import get_vector_search_results
                vector_results = get_vector_search_results(query)
                mongodb_results = get_structured_search_results(query)
                graph_results = get_graph_search_results(query)
                
                search_results = {
                    "vector": vector_results,
                    "structured": mongodb_results,
                    "graph": graph_results
                }
                
                # ä½¿ç”¨åˆ—å¸ƒå±€æ˜¾ç¤ºæ‰€æœ‰ç»“æœ
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.write("ğŸ” å‘é‡æœç´¢ç»“æœ:")
                    if vector_results:
                        # ä½¿ç”¨ LLM ç”Ÿæˆå‘é‡æœç´¢ç»“æœçš„æ€»ç»“
                        try:
                            client = OpenAI(
                                api_key="sk-1pUmQlsIkgla3CuvKTgCrzDZ3r0pBxO608YJvIHCN18lvOrn",
                                base_url="https://api.chatanywhere.tech/v1",
                                timeout=60
                            )
                            
                            # å‡†å¤‡æç¤ºè¯
                            prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹æœç´¢ç»“æœå›ç­”é—®é¢˜ï¼š
                            
                            é—®é¢˜: {query}
                            
                            æœç´¢ç»“æœ:
                            {vector_results}
                            
                            è¯·ç®€æ´åœ°æ€»ç»“ç›¸å…³ä¿¡æ¯ã€‚å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œè¯·ç›´æ¥è¯´æ˜ã€‚"""
                            
                            response = client.chat.completions.create(
                                model="gpt-4o-mini-2024-07-18",
                                messages=[
                                    {
                                        "role": "system", 
                                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—åŠ©æ‰‹ï¼Œè¯·ç®€æ´åœ°æ€»ç»“æœç´¢ç»“æœã€‚"
                                    },
                                    {
                                        "role": "user", 
                                        "content": prompt
                                    }
                                ],
                                temperature=0.1
                            )
                            st.info(response.choices[0].message.content)
                        except Exception as e:
                            st.error(f"ç”Ÿæˆå‘é‡æœç´¢æ€»ç»“å¤±è´¥: {str(e)}")
                            st.write("æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
                    else:
                        st.write("æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
                
                with col2:
                    st.write("ğŸ“Š MongoDBæœç´¢ç»“æœ:")
                    if mongodb_results:
                        for result in mongodb_results:
                            st.info(result)
                    else:
                        st.write("æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
                
                with col3:
                    st.write("ğŸ•¸ï¸ å›¾æ•°æ®åº“æœç´¢ç»“æœ:")
                    if graph_results:
                        for result in graph_results:
                            st.info(result)
                    else:
                        st.write("æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
            
            # ä½¿ç”¨LLMç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
            st.write("ğŸ¤– AI åˆ†æä¸å›ç­”:")
            with st.spinner("AIæ­£åœ¨åˆ†ææœç´¢ç»“æœ..."):
                max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
                retry_count = 0
                
                while retry_count < max_retries:
                    try:
                        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼Œä½¿ç”¨æ–°çš„é…ç½®
                        client = OpenAI(
                            api_key="sk-1pUmQlsIkgla3CuvKTgCrzDZ3r0pBxO608YJvIHCN18lvOrn",
                            base_url="https://api.chatanywhere.tech/v1",
                            timeout=60  # å¢åŠ è¶…æ—¶æ—¶é—´
                        )
                        
                        # å‡†å¤‡æç¤ºè¯
                        prompt = f"""è¯·åŸºäºä»¥ä¸‹ç›¸å…³å†…å®¹å›ç­”é—®é¢˜ï¼š
                        
                        ç”¨æˆ·é—®é¢˜: {query}
                        
                        ç›¸å…³å†…å®¹:
                        {search_results}
                        
                        è¯·æ³¨æ„ï¼š
                        1. åªä½¿ç”¨æä¾›çš„ç›¸å…³å†…å®¹å›ç­”é—®é¢˜
                        2. å¦‚æœç›¸å…³å†…å®¹ä¸­æ²¡æœ‰ç­”æ¡ˆï¼Œè¯·æ˜ç¡®è¯´æ˜
                        3. ä¸è¦æ·»åŠ ä»»ä½•ä¸åœ¨ç›¸å…³å†…å®¹ä¸­çš„ä¿¡æ¯
                        4. ä¿æŒå›ç­”çš„å‡†ç¡®æ€§å’Œå®¢è§‚æ€§"""
                        
                        response = client.chat.completions.create(
                            model="gpt-4o-mini-2024-07-18",  # ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹
                            messages=[
                                {
                                    "role": "system", 
                                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—åŠ©æ‰‹ï¼Œæ“…é•¿è§£è¯»åŒ»ç–—ä¿¡æ¯å¹¶æä¾›å‡†ç¡®çš„è§£ç­”ã€‚"
                                },
                                {
                                    "role": "user", 
                                    "content": prompt
                                }
                            ],
                            temperature=0.1
                        )
                        
                        answer = response.choices[0].message.content
                        st.success(answer)
                        
                        # æ›´æ–°å¯¹è¯å†å²
                        st.session_state.chat_history.append({
                            "query": query,
                            "response": answer,
                            "search_results": search_results,
                            "search_type": search_type
                        })
                        
                        break  # æˆåŠŸåè·³å‡ºå¾ªç¯
                        
                    except Exception as e:
                        retry_count += 1
                        if retry_count == max_retries:
                            st.error(f"ç”Ÿæˆå›ç­”å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")
                            st.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                            st.error(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
                            # æä¾›ä¸€ä¸ªåŸºæœ¬çš„å›ç­”
                            basic_answer = "æŠ±æ­‰ï¼Œå½“å‰æ— æ³•è¿æ¥åˆ°AIæœåŠ¡ã€‚æ ¹æ®æœç´¢ç»“æœï¼Œ"
                            if search_results.get('structured'):
                                basic_answer += "æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼š\n" + "\n".join(search_results['structured'])
                            else:
                                basic_answer += "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
                            st.info(basic_answer)
                        else:
                            st.warning(f"ç¬¬ {retry_count} æ¬¡å°è¯•å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•...")
                            time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•

# ä¿®æ”¹å¯¹è¯å†å²æ˜¾ç¤ºéƒ¨åˆ†
st.subheader("ğŸ’¬ å¯¹è¯å†å²")
for chat in st.session_state.chat_history:
    with st.expander(f"é—®é¢˜ï¼š{chat['query'][:50]}..."):
        st.write("ğŸ—£ï¸ ç”¨æˆ·é—®é¢˜ï¼š")
        st.info(chat["query"])
        
        st.write(f" æ£€ç´¢æ–¹å¼ï¼š{chat['search_type']}")
        
        # æ˜¾ç¤ºæœç´¢ç»“æœ
        if "search_results" in chat:
            if chat['search_type'] == "æ··åˆæ£€ç´¢":
                tabs = st.tabs(["å‘é‡æœç´¢", "MongoDB", "å›¾æ•°æ®åº“"])
                with tabs[0]:
                    if "vector" in chat["search_results"]:
                        for result in chat["search_results"]["vector"]:
                            st.write(result)
                    else:
                        st.write("æ— å‘é‡æœç´¢ç»“æœ")
                with tabs[1]:
                    if "structured" in chat["search_results"]:
                        for result in chat["search_results"]["structured"]:
                            st.write(result)
                    else:
                        st.write("æ— MongoDBæœç´¢ç»“æœ")
                with tabs[2]:
                    if "graph" in chat["search_results"]:
                        for result in chat["search_results"]["graph"]:
                            st.write(result)
                    else:
                        st.write("æ— å›¾æ•°æ®åº“æœç´¢ç»“æœ")
            else:
                # æ˜¾ç¤ºå•ä¸€æ•°æ®åº“çš„ç»“æœ
                key_map = {
                    "å‘é‡æ•°æ®åº“": "vector",
                    "MongoDB": "structured",
                    "å›¾æ•°æ®åº“": "graph"
                }
                key = key_map.get(chat['search_type'])
                if key and key in chat["search_results"]:
                    for result in chat["search_results"][key]:
                        st.write(result)
                else:
                    st.write("æ— æœç´¢ç»“æœ")
        
        st.write("ğŸ¤– AI å›ç­”ï¼š")
        st.success(chat["response"])

def setup_graph(parser):
    G = nx.Graph()
    
    # æ·»åŠ æ‚£è€…èŠ‚ç‚¹ï¼ˆå¸¦æ›´å¤šå±æ€§ï¼‰
    G.add_node(parser.parsed_data['name'], 
               type="patient",
               age=parser.parsed_data['age'],
               gender=parser.parsed_data['gender'],
               chief_complaint=parser.parsed_data['chief_complaint'])
    
    # æ·»åŠ ç—‡çŠ¶èŠ‚ç‚¹ï¼ˆå¸¦è¯¦ç»†ä¿¡æ¯ï¼‰
    for symptom in parser.parsed_data['symptoms']:
        symptom_id = f"{symptom['symptom']}_{parser.parsed_data['name']}"
        G.add_node(symptom_id, 
                  type="symptom",
                  description=symptom['description'])
        G.add_edge(parser.parsed_data['name'], symptom_id, 
                  relationship="has_symptom",
                  onset_date=symptom['onset_date'])
    
    # æ·»åŠ æ£€æŸ¥ç»“æœèŠ‚ç‚¹ï¼ˆå¸¦å¼‚å¸¸æ ‡è®°ï¼‰
    for exam_type, exam_data in parser.parsed_data['examinations'].items():
        exam_id = f"{exam_type}_{parser.parsed_data['name']}"
        G.add_node(exam_id,
                  type="examination",
                  result=exam_data['result'],
                  abnormal=exam_data['abnormal'])
        G.add_edge(parser.parsed_data['name'], exam_id,
                  relationship="underwent")
        
        # æ·»åŠ æ£€ç»“æœä¸ç—‡çŠ¶çš„å…³è”
        for symptom in parser.parsed_data['symptoms']:
            symptom_id = f"{symptom['symptom']}_{parser.parsed_data['name']}"
            if any(word in exam_data['description'] for word in symptom['symptom'].split()):
                G.add_edge(exam_id, symptom_id,
                          relationship="confirms")
    
    # æ·»åŠ æ²»ç–—èŠ‚ç‚¹
    for treatment in parser.parsed_data['treatments']:
        treatment_id = f"{treatment['medication']}_{parser.parsed_data['name']}"
        G.add_node(treatment_id,
                  type="treatment",
                  medication=treatment['medication'],
                  dosage=treatment['dosage'])
        G.add_edge(parser.parsed_data['name'], treatment_id,
                  relationship="receives")

def clean_vector_store():
    """æ¸…ç†å‘é‡æ•°æ®åº“"""
    try:
        st.session_state.file_chunks = {}
        st.session_state.file_indices = {}
        st.success("âœ… å‘é‡æ•°æ®åº“å·²æ¸…ç©º")
        return True
    except Exception as e:
        st.error(f"æ¸…ç†å‘é‡æ•°æ®åº“é”™è¯¯: {str(e)}")
        return False

def clean_mongodb_data():
    """æ¸…ç†MongoDBä¸­çš„æ‰€æœ‰æ•°æ®"""
    try:
        db = get_mongodb_connection()
        if db is not None:
            result = db.patients.delete_many({})
            st.write(f"å·²åˆ é™¤æ‰€æœ‰è®°å½•ï¼ˆå…± {result.deleted_count} æ¡ï¼‰")
            st.success("âœ… MongoDBå·²å®Œå…¨æ¸…ç©º")
            
            if 'mongodb_records' in st.session_state:
                st.session_state.mongodb_records = []
            if 'structured_data' in st.session_state:
                st.session_state.structured_data = {}
            
            return True
    except Exception as e:
        st.error(f"æ¸…ç†MongoDBé”™è¯¯: {str(e)}")
        return False

def clean_graph_data():
    """æ¸…ç†å›¾æ•°æ®åº“"""
    try:
        if os.path.exists("medical_graph.gexf"):
            os.remove("medical_graph.gexf")
        st.success("âœ… å›¾æ•°æ®åº“å·²æ¸…ç©º")
        return True
    except Exception as e:
        st.error(f"æ¸…ç†å›¾æ•°æ®åº“é”™è¯¯: {str(e)}")
        return False

# åœ¨ä¾§è¾¹æ æ·»åŠ æ¸…ç†æŒ‰é’®
with st.sidebar:
    # é€‰æ‹©è¦æ¸…ç©ºçš„æ•°æ®åº“
    clean_db = st.selectbox(
        "é€‰æ‹©è¦æ¸…ç©ºçš„æ•°æ®åº“",
        ["å‘é‡æ•°æ®åº“", "MongoDB", "å›¾æ•°æ®åº“", "å…¨éƒ¨æ•°æ®åº“"]
    )
    
    if st.button("æ¸…ç©ºæ•°æ®"):
        if clean_db == "å‘é‡æ•°æ®åº“":
            if clean_vector_store():
                st.rerun()
        elif clean_db == "MongoDB":
            if clean_mongodb_data():
                st.rerun()
        elif clean_db == "å›¾æ•°æ®åº“":
            if clean_graph_data():
                st.rerun()
        else:  # æ¸…ç©ºæ‰€æœ‰æ•°æ®åº“
            success = True
            if not clean_vector_store():
                success = False
            if not clean_mongodb_data():
                success = False
            if not clean_graph_data():
                success = False
            
            if success:
                st.success("âœ… æ‰€æœ‰æ•°æ®åº“å·²æ¸…ç©ºï¼")
                st.rerun()
            else:
                st.error("éƒ¨åˆ†æ•°åº“æ¸…ç©ºå¤±è´¥ï¼")